<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Do Language Models Actually Understand Language? - Notes on Machine Learning, Technology, and Philosophy</title>
    <meta name="description" content="Reflections on machine learning, AI research, technology, and philosophy by Aarne Talman.">
    <meta name="author" content="Aarne Talman">
    <link rel="canonical" href="https://talman.fi/posts/ai-language-understanding.html">
    <link rel="alternate" type="application/rss+xml" title="Notes on Machine Learning, Technology, and Philosophy RSS Feed" href="https://talman.fi/rss.xml">
    <link rel="alternate" type="application/atom+xml" title="Notes on Machine Learning, Technology, and Philosophy Atom Feed" href="https://talman.fi/atom.xml">
    <style>
:root {
  --block-spacing: 2rem; /* header padding & nav top padding */
  --nav-border-w: 1px; /* keep in sync with nav border width */
}

* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
  line-height: 1.6;
  font-size: 1rem; /* base size */
  color: #e2e8f0;
  max-width: 1000px;
  margin: 0 auto;
  padding: 2rem 1rem;
  background: #0f172a;
  min-height: 100vh;
}

header {
  border: 2px solid #334155;
  margin-bottom: 1.5rem;
  padding: var(--block-spacing);
  background: rgba(30, 41, 59, 0.4);
}

/* Site title */
h1 {
  font-size: clamp(1.5rem, 4vw, 2rem);
  font-weight: 700;
  margin-bottom: 0.5rem;
  color: #e2e8f0;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
  letter-spacing: -0.02em;
}

/* Subtitle under site title */
.subtitle {
  color: #94a3b8;
  font-size: clamp(0.85rem, 2vw, 1rem);
  margin-bottom: 1.5rem;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
}

nav {
  margin-top: var(--block-spacing);   /* separates it from header border */
  border-top: 1px solid #334155;
  padding-top: var(--block-spacing);  /* equal distance top → text */
}

nav a {
  color: #60a5fa;
  text-decoration: none;
  margin-right: 2rem;
  font-weight: 500;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
  border-bottom: 1px solid transparent;
  transition: border-bottom-color 0.2s ease;
}

nav a:hover {
  border-bottom-color: #60a5fa;
}

nav a:before {
  content: '> ';
  color: #94a3b8;
}

.feed-links {
  margin-top: 0.5rem;
  font-size: 0.85rem;
  color: #94a3b8;
}

footer .feeds {
  margin-top: 0.5rem;
  font-size: 0.8rem;
  color: #94a3b8;
}

footer .feeds a {
  color: inherit;
  text-decoration: none;
  margin-right: 1rem;
  border-bottom: 1px solid transparent;
}

footer .feeds a:hover {
  border-bottom-color: #60a5fa;
}

main {
  margin-bottom: 3rem;
}

.category-filter {
  margin-bottom: 1rem;
}

.filter-label {
  color: #94a3b8;
  font-size: 0.9rem;
  margin-right: 1rem;
}

.filter-label:before {
  content: '> ';
  color: #334155;
}

.category-btn {
  background: #0f172a;
  color: #94a3b8;
  border: 1px solid #334155;
  padding: 0.3rem 0.8rem;
  margin-right: 0.5rem;
  margin-bottom: 0.5rem;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
  font-size: 0.85rem;
  cursor: pointer;
  transition: all 0.2s ease;
}

.category-btn:hover {
  color: #e2e8f0;
  border-color: #60a5fa;
}

.category-btn.active {
  background: #60a5fa;
  color: #0f172a;
  border-color: #60a5fa;
}

.post-list li.hidden {
  display: none;
}

.post-list {
  list-style: none;
}

.post-list li {
  margin-bottom: 1.5rem;
  padding: 1.5rem;
  background: rgba(30, 41, 59, 0.4);
  border: 1px solid #334155;
  position: relative;
}

.post-list li:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  height: 2px;
  background: #60a5fa;
}

/* Post title in list */
.post-title {
  font-size: clamp(1.2rem, 3vw, 1.5rem);
  margin-bottom: 0.5rem;
  font-weight: 600;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
}

.post-title a {
  color: #e2e8f0;
  text-decoration: none;
}

.post-title a:hover {
  color: #60a5fa;
}

.post-title a:before {
  content: '# ';
  color: #94a3b8;
}

.post-date {
  color: #94a3b8;
  font-size: 0.85rem;
  margin-bottom: 0.75rem;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
}

.post-excerpt {
  color: #cbd5e1;
  line-height: 1.6;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
}

/* Article container (shared for posts & pages) */
.entry {
  background: rgba(30, 41, 59, 0.4);
  padding: 2.5rem;
  border: 2px solid #334155;
  position: relative;
}

.entry::before {
  content: '';
  position: absolute;
  top: 0; left: 0; right: 0;
  height: 3px;
  background: #60a5fa;
}

/* Meta row for posts only */
.post-meta {
  color: #94a3b8;
  font-size: 0.85rem;
  margin-bottom: 2rem;
  padding-bottom: 1rem;
  border-bottom: 1px solid #334155;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
}

.post-meta::before {
  content: '// ';
  color: #334155;
}

.date-text {
  display: inline;
  margin-right: 1rem;
}

.categories {
  display: inline-flex;
  flex-wrap: wrap;
  gap: 0.5rem;
  align-items: baseline;
}

/* Content styling - SHARED for all posts and pages */
.content h1 {
  margin: 0 0 1.5rem 0;
  font-size: clamp(1.5rem, 3vw, 2rem);
  color: #e2e8f0;
  font-weight: 700;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
}

.content h1::before { 
  content: '# '; 
  color: #94a3b8; 
}

.content h2 {
  margin: 2rem 0 1rem 0;
  font-size: clamp(1.25rem, 2.5vw, 1.6rem);
  color: #e2e8f0;
  font-weight: 600;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
}

.content h2::before { 
  content: '## '; 
  color: #94a3b8; 
}

.content h3 {
  margin: 1.5rem 0 0.75rem 0;
  font-size: clamp(1.1rem, 2vw, 1.3rem);
  color: #e2e8f0;
  font-weight: 600;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
}

.content h3::before { 
  content: '### '; 
  color: #94a3b8; 
}

/* Body text styling - SHARED for all posts and pages */
.content p {
  margin-bottom: 1.5rem;
  line-height: 1.7;
  color: #cbd5e1;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
  font-size: 1rem;
}

.category {
  background: #0f172a;
  color: #60a5fa;
  padding: 0.2rem 0.5rem;
  border: 1px solid #334155;
  font-size: 0.75rem;
  margin-right: 0.5rem;
}

.content strong {
  color: #e2e8f0;
  font-weight: 600;
}

.content img {
  max-width: 100%;
  height: auto;
  margin: 2rem 0;
  border: 2px solid #334155;
}

.content img[src*="about/aarne"] {
  max-width: 200px;
  border-radius: 8px;
  float: left;
  margin: 0 2rem 1rem 0;
}

.content a {
  color: #60a5fa;
  text-decoration: none;
  border-bottom: 1px solid transparent;
  transition: border-bottom-color 0.2s ease;
}

.content a:hover {
  border-bottom-color: #60a5fa;
}

.content pre {
  background: #0f172a;
  padding: 1.5rem;
  overflow-x: auto;
  margin: 2rem 0;
  border: 1px solid #334155;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
}

.content code {
  background: #0f172a;
  color: #94a3b8;
  padding: 0.2rem 0.4rem;
  font-size: 0.9rem;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
  border: 1px solid #334155;
}

.content pre code {
  background: none;
  padding: 0;
  border: none;
  color: #e2e8f0;
}

.content blockquote {
  border-left: 3px solid #60a5fa;
  margin: 2rem 0;
  padding-left: 1.5rem;
  color: #94a3b8;
  background: #0f172a;
  padding: 1rem 1.5rem;
  font-style: italic;
}

.content blockquote:before {
  content: '> ';
  color: #60a5fa;
  font-weight: bold;
}

.content ul,
.content ol {
  margin: 1.5rem 0;
  padding-left: 0;
  color: #cbd5e1;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
  list-style: none;
}

.content li {
  margin-bottom: 1rem;
  line-height: 1.6;
  padding-left: 1.5rem;
  position: relative;
}

.content ul li:before {
  content: '• ';
  color: #60a5fa;
  font-weight: bold;
  position: absolute;
  left: 0;
}

.content ol {
  counter-reset: list-counter;
}

.content ol li {
  counter-increment: list-counter;
}

.content ol li:before {
  content: counter(list-counter) '. ';
  color: #60a5fa;
  font-weight: bold;
  position: absolute;
  left: 0;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
}

footer {
  padding-top: 2rem;
  text-align: center;
  color: #94a3b8;
  font-size: 0.85rem;
  padding: 2rem;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
}

footer:before {
  content: '---';
  white-space: pre;
  color: #334155;
  display: block;
  text-align: center;
  margin-bottom: 1rem;
}

footer a {
  color: #60a5fa;
  text-decoration: none;
  border-bottom: 1px solid transparent;
  transition: border-bottom-color 0.2s ease;
}

footer a:hover {
  border-bottom-color: #60a5fa;
}

/* Simple scrollbar */
::-webkit-scrollbar {
  width: 12px;
}

::-webkit-scrollbar-track {
  background: #0f172a;
  border: 1px solid #334155;
}

::-webkit-scrollbar-thumb {
  background: #334155;
}

::-webkit-scrollbar-thumb:hover {
  background: #60a5fa;
}

/* Small screens: layout tweaks only (typography scales via clamp) */
@media (max-width: 600px) {
  :root {
    --block-spacing: 1.5rem; /* keep header & nav equal on mobile */
  }

  body {
    padding: 1rem 0.5rem;
    font-size: 0.95rem;
  }

  header,
  article,
  footer {
    padding: 1.5rem;
  }

  .post-list li {
    padding: 1.5rem;
  }

  /* Mobile navigation: horizontal scrollable */
  nav {
    overflow-x: auto;
    scrollbar-width: none;
    -ms-overflow-style: none;
    white-space: nowrap;
  }

  nav::-webkit-scrollbar {
    display: none;
  }

  nav a {
    display: inline-block;
    margin-right: 1.5rem;
    margin-bottom: 0;
    white-space: nowrap;
  }

  /* Mobile categories: horizontal scrollable */
  .category-filter {
    overflow-x: auto;
    scrollbar-width: none;
    -ms-overflow-style: none;
    white-space: nowrap;
    padding-bottom: 0.5rem;
  }

  .category-filter::-webkit-scrollbar {
    display: none;
  }

  .category-btn {
    display: inline-block;
    margin-right: 0.75rem;
    margin-bottom: 0;
    white-space: nowrap;
  }

  /* Better mobile post metadata layout */
  .date-text {
    display: inline;        /* keep on same line as '//' */
    margin-right: 0.75rem;  /* small gap before categories */
    margin-bottom: 0.5rem;       /* no forced line break */
  }

  .categories {
    display: flex;
    margin-top: 0.5rem;
    gap: 0; /* Remove gap to align first category to left edge */
  }

  .categories .category {
    margin-right: 0.5rem; /* Add manual spacing between categories */
  }

  .categories .category:last-child {
    margin-right: 0; /* Remove margin from last category */
  }

  /* Mobile-friendly content headings */
  .content h1 {
    line-height: 1.2;
    word-break: break-word;
    hyphens: auto;
  }

  .content h2 {
    line-height: 1.3;
    word-break: break-word;
    hyphens: auto;
  }

  .content h3 {
    line-height: 1.4;
    word-break: break-word;
    hyphens: auto;
  }

  /* Better mobile text wrapping */
  .content p {
    word-break: break-word;
    hyphens: auto;
  }

  /* Add visual hint for scrollable content */
  .category-filter::after {
    content: '';
    position: absolute;
    top: 0;
    right: 0;
    width: 20px;
    height: 100%;
    background: linear-gradient(to right, transparent, rgba(30, 41, 59, 0.4));
    pointer-events: none;
  }

  nav::after {
    content: '';
    position: absolute;
    top: 0;
    right: 0;
    width: 20px;
    height: 100%;
    background: linear-gradient(to right, transparent, rgba(30, 41, 59, 0.4));
    pointer-events: none;
  }

  /* Make scrollable containers relative for ::after positioning */
  .category-filter,
  nav {
    position: relative;
  }

  .feed-links {
    margin-top: 0.5rem;
    padding-top: 0.5rem;
  }

  .feed-links a {
    display: inline-block;
    margin-right: 1rem;
    margin-bottom: 0.25rem;
  }
}
</style>
</head>
<body>
    <header>
      <h1><a href="/" style="color: inherit; text-decoration: none;">Notes on Machine Learning, Technology, and Philosophy</a></h1>
      <p class="subtitle">By Aarne Talman</p>
      <nav><a href="/">Home</a><a href="/posts/about.html">About</a><a href="https://github.com/aarnetalman" target="_blank" rel="noopener">GitHub</a><a href="https://scholar.google.com/citations?hl=en&user=Vhq5-s0AAAAJ" target="_blank" rel="noopener">Google Scholar</a></nav>
    </header>

    
    <main>
        
    <article class="entry">
      <div class="post-meta">
        <span class="date-text"><time datetime="2025-09-13T00:00:00.000Z">September 13, 2025</time></span>
        
          <span class="categories">
            <span class="category">Machine Learning</span> <span class="category">Philosophy</span>
          </span>
      </div>
      <div class="content">
        <h1>Do language models Actually Understand Language?</h1>
<p><em>Originally posted in <a href="https://medium.com/@aarnetalman/do-ai-models-actually-understand-language-ce2f4e9a7fb9">Medium</a></em></p>
<p>By now, most people are well aware of how proficient language models like GPT-4, Claude, and Gemini are at tasks requiring various linguistic skills and knowledge. These language models can write essays, summarise complex documents, and even pass standardised tests, demonstrating impressive capabilities. But to what extent do models with such skills truly understand language, or are they merely exceptionally good at mimicking it?</p>
<p>I explored this question extensively in my <a href="http://urn.fi/URN:ISBN:978-951-51-9581-4">PhD thesis</a>, but in this blog post I aim to provide a more concise summary of the key takeaways, and hopefully nudge readers to think about these more fundamental and philosophical aspects of AI instead of the constant race to the top of the leaderboards.</p>
<h2>What Do We Mean by &quot;Understanding&quot;?</h2>
<p>Philosophers, linguists, and cognitive scientists have debated the nature of language understanding for centuries. Language understanding has traditionally been thought of a capability that only humans possess, however, recently language understanding has also been studied as a capability that machine learning models and AI systems could be said to achieve. I will not cover all the different accounts of human language understanding here, but will focus on two main perspectives that emerge from recent AI and natural language understanding (NLU) literature.</p>
<p>The two accounts are:</p>
<p><strong>The Usage-Based Definition</strong>: Understanding is the ability to use language effectively in complex tasks. This approach assumes that language understanding can be measured through various proxy tasks, like question answering (QA) or natural language inference (NLI).</p>
<p><strong>The Intent-Based Definition</strong>: Understanding goes beyond task performance. It involves grasping the speaker&#39;s intent, like their underlying goals or emotions.</p>
<p>The usage-based definition is what is often implicitly assumed in NLU research. When companies and researchers compare their models&#39; language understanding capabilities with other models, this is mostly done by comparing scores on evaluation benchmarks and tasks. Consider this example from the <a href="https://arxiv.org/abs/1810.04805">BERT paper</a>:</p>
<blockquote>
<p>In order to train a model that understands sentence relationships, we pre-train for a binarized next sentence prediction task that can be trivially generated from any monolingual corpus [...] Despite its simplicity, we demonstrate [...] that pre-training towards this task is very beneficial to both QA and NLI.</p>
</blockquote>
<p>In this example the authors implicitly assume that QA and NLI tasks are examples of tasks that require understanding, but they don&#39;t give any explicit definition of language understanding.</p>
<p>The usage-based account of language understanding is problematic in the sense that it does not really specify what capabilities a model should have in order to understand language. Is a model that performs well in text summarisation but fails in other tasks able to understand language or do different tasks test different degrees of language understanding?</p>
<p>The intent-based definition assumes that language understanding requires intents. These intents are often taken to be about a mental representation, a model of the world, and this model is used in comprehending language and in communication. Successful communication, in this view, requires a grasp of the communicative intent of the speaker. There are various formulations of the intent-based approach. One clear example can be found form the work of psychologists <a href="https://doi.org/10.3758/s13421-016-0619-6">Pettison and Radvansky</a>:</p>
<blockquote>
<p>During text comprehension, readers create mental representations of the described events, called situation models. When new information is encountered, these models must be updated or new ones created.</p>
</blockquote>
<p>The main problem with the intent-based definition is that it relies on the definition of intent, which itself is a difficult term to define. In philosophy, intention is often defined as something like &quot;the power of minds and mental states to be about, to represent, or to stand for things, properties, and states of affair&quot; <a href="https://plato.stanford.edu/entries/intention/">Setiya 2022</a>. Could we ascribe intention to language models given this definition?</p>
<h2>The Limits of Current Benchmarks</h2>
<p>Before exploring whether language models could be said to have intents, let&#39;s discuss the limitations of NLU evaluation benchmarks. Most NLU models are evaluated on benchmarks such as <a href="https://arxiv.org/abs/2009.03300v3">MMLU</a> or <a href="https://super.gluebenchmark.com/">SuperGLUE</a>. These benchmarks measure performance on specific tasks, such as natural language inference or question-answering. High scores on these tasks are often seen as evidence of language understanding.</p>
<p>However, research suggests that these benchmarks may not be reliable indicators of true understanding. Studies have shown that NLU models can perform well on these tasks even when the word order of sentences is scrambled <a href="https://arxiv.org/abs/2012.15180">Pham et al. 2020</a> or if words are removed from sentences <a href="https://arxiv.org/abs/2104.04751">Talman et al. 2021</a>, <a href="https://arxiv.org/abs/2201.04467">2022</a>. These results suggest that models might be relying on statistical patterns and shortcuts rather than deep language understanding.</p>
<h2>The Role of Intent</h2>
<p>Given that the usage-based account does not really give us a definition of what language understanding is and, moreover, given that the current tasks and benchmarks don&#39;t necessarily measure understanding, let&#39;s focus a bit more on the intent-based account.</p>
<p>The intent-based definition of understanding presents a different challenge. Can language models, which are fundamentally statistical machines, grasp the nuanced intentions behind human communication?</p>
<p>Some argue that they can. According to them, neural networks learn representations of the world from the data they&#39;re trained on. These representations could be seen as a form of understanding. When a model generates a response, it&#39;s drawing upon its learned representation of the world to predict the most appropriate answer. A clear argument in this direction is made by Ilya Sutskever in his <a href="https://blogs.nvidia.com/blog/sutskever-openai-gtc/">fireside chat</a> with the founder and CEO of NVIDIA, Jensen Huang:</p>
<blockquote>
<p>[W]hat the neural net learns is some representation of the process that produced the text, and that&#39;s a projection of the world.</p>
</blockquote>
<p>Others argue that this is not true understanding. Human understanding involves a lifetime of embodied experiences and complex cognitive processes. While language models can learn impressive representations, they might still lack the depth and richness of human understanding.</p>
<h2>A New Kind of Understanding?</h2>
<p>The rise of AI may force us to reconsider what it means to understand language.</p>
<p>Mitchell and Krakauer hypothesise in their <a href="https://arxiv.org/abs/2210.13966">recent survey</a> that AI has created new forms of understanding. Where we have earlier considered language understanding to be only of the kind that we humans possess, there likely are other forms of language understanding that could more easily be attributed to artificial systems, like NLU models.</p>
<p>It is possible that language models possess a unique form of understanding that is different from our own. This new kind of understanding might not involve emotions or consciousness, but it could still be incredibly powerful and valuable.</p>
<h2>What&#39;s Next?</h2>
<p>So where do I stand in this debate? Do I think current language models understand language? Before I can answer this question I think we need two things:</p>
<p><strong>A clear definition of what language understanding (for AI) is</strong></p>
<p><strong>Better evaluation benchmarks that capture and measure understanding according to the above definition</strong></p>
<p>The current evaluation benchmarks for natural language understanding models are clearly limited (as discussed above). To truly gauge a model&#39;s understanding, we need better evaluation methods that go beyond simple task performance. These methods should assess a model&#39;s ability to reason, use common sense knowledge, and interpret the subtle nuances of human communication.</p>
<p>We have started to explore different approaches to evaluate language models in our <a href="https://eloquent-lab.github.io">ELOQUENT Lab</a> shared task. The first results will be presented later this year at <a href="https://clef2024.clef-initiative.eu">CLEF 2024</a> and we plan to make the ELOQUENT Lab an annual shared task.</p>
<p>In addition to better evaluation benchmarks, we also need more fundamental research on the nature of language understanding and language models&#39; capabilities to understand language.</p>

      </div>
    </article>
  
    </main>
    
    <footer>
      <p>&copy; 2025 Aarne Talman. All rights reserved.</p>
      <p><a href="/rss.xml">/rss</a> <a href="/atom.xml">/atom</a></p>
      <p>Powered by MonoBlogger</p>
  </footer>
    
</body>
</html>